import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import torch
import torch.nn as nn
import torch.optim as optim

# ========= 1ï¸âƒ£ è®€å– Excel è³‡æ–™ =========
data = pd.read_excel("weather_data.xlsx")  # â¬…ï¸ ç¢ºä¿æª”åæ­£ç¢º
print("âœ… å·²æˆåŠŸè®€å–è³‡æ–™ï¼š")
print(data.head())

# ========= 2ï¸âƒ£ æ­£è¦åŒ–èˆ‡åºåˆ—å»ºæ§‹ =========
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

def create_sequences(data, seq_len):
    xs, ys = [], []
    for i in range(len(data) - seq_len):
        x = data[i:i+seq_len]
        y = data[i+seq_len]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

seq_len = 7
X, y = create_sequences(data_scaled, seq_len)

train_size = int(len(X) * 0.8)
X_train, y_train = X[:train_size], y[:train_size]
X_test, y_test = X[train_size:], y[train_size:]

X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32)

# ========= 3ï¸âƒ£ æ¨¡å‹å®šç¾© =========
class WeatherLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(WeatherLSTM, self).__init__()
        ### ğŸ”§ ä¿®æ”¹ï¼šå°‡å¤šå±¤ LSTM æ”¯æ´çš„åƒæ•¸åŠ é€²ä¾†ï¼ˆnum_layersï¼‰
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)

        # â—æ”¹é€²å»ºè­°ï¼šå¦‚æœä½ è¦åŠ  Dropoutï¼Œå¯å¯«æˆï¼š
        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=0.2, batch_first=True)

        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])  # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥çš„è¼¸å‡ºä½œç‚ºé æ¸¬çµæœ

# -------- å»ºç«‹æ¨¡å‹èˆ‡è¨“ç·´å…ƒä»¶ --------
input_size = 3
hidden_size = 64
output_size = 3
### ğŸ”§ ä¿®æ”¹ï¼šæ”¹ç‚ºå¤šå±¤ LSTM çš„å±¤æ•¸
num_layers = 2

model = WeatherLSTM(input_size, hidden_size, output_size, num_layers)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# ========= 4ï¸âƒ£ è¨“ç·´æ¨¡å‹ =========
epochs = 100
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    output = model(X_train)
    loss = criterion(output, y_train)
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}")

# ========= 5ï¸âƒ£ é æ¸¬èˆ‡åæ¨™æº–åŒ– =========
model.eval()
with torch.no_grad():
    train_pred = model(X_train).numpy()
    test_pred = model(X_test).numpy()

train_pred_rescaled = scaler.inverse_transform(train_pred)
y_train_rescaled = scaler.inverse_transform(y_train.numpy())
test_pred_rescaled = scaler.inverse_transform(test_pred)
y_test_rescaled = scaler.inverse_transform(y_test.numpy())

# ========= 6ï¸âƒ£ ç•«åœ– =========
predicted_df = pd.DataFrame(test_pred_rescaled, columns=['temperature', 'humidity', 'wind_speed'])
actual_df = pd.DataFrame(y_test_rescaled, columns=['temperature', 'humidity', 'wind_speed'])

colors = ['#1f77b4', '#ff7f0e']
fig, axes = plt.subplots(3, 1, figsize=(12, 10))
fig.suptitle('Weather Prediction Using LSTM', fontsize=16, weight='bold')

labels = ['Temperature (Â°C)', 'Humidity (%)', 'Wind Speed (km/h)']
cols = ['temperature', 'humidity', 'wind_speed']

for i in range(3):
    axes[i].plot(actual_df[cols[i]], color=colors[0], label='Actual')  # å¯¦éš›å€¼
    axes[i].plot(predicted_df[cols[i]], color=colors[1], label='Predicted')  # æ”¹æˆå¯¦ç·šé æ¸¬å€¼
    axes[i].set_title(f'{cols[i].capitalize()} Prediction', fontsize=14, weight='bold')
    axes[i].set_ylabel(labels[i], fontsize=12)
    axes[i].legend(fontsize=10)
    axes[i].grid(alpha=0.3)


axes[2].set_xlabel('Days', fontsize=12)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# ========= 7ï¸âƒ£ è©•ä¼°æŒ‡æ¨™ =========
icons = ['ğŸŒ¡ï¸', 'ğŸ’§', 'ğŸƒ']
print("\nğŸ” æ¨¡å‹é æ¸¬æŒ‡æ¨™è©•ä¼°ï¼ˆæ¯å€‹è®Šæ•¸ï¼‰:")
for i, label in enumerate(cols):
    y_true = y_test_rescaled[:, i]
    y_pred = test_pred_rescaled[:, i]

    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    print(f"{icons[i]} {label.capitalize()}:")
    print(f"   âœ… RMSE  : {rmse:.3f}")
    print(f"   âœ… MAE   : {mae:.3f}")
    print(f"   âœ… RÂ²    : {r2:.4f}")
    print(f"   âœ… MAPE  : {mape:.2f}%\n")
# é€™æ®µç¨‹å¼ç¢¼æ˜¯ç”¨ä¾†è¨“ç·´ä¸€å€‹ LSTM æ¨¡å‹ä¾†é æ¸¬æ°£è±¡è³‡æ–™ï¼Œä¸¦ä¸”å°‡çµæœå¯è¦–åŒ–å’Œè©•ä¼°æ¨¡å‹çš„è¡¨ç¾ã€‚
# ä½ å¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´æ¨¡å‹çš„åƒæ•¸ã€è¨“ç·´çš„ epochs æ•¸é‡ç­‰ã€‚